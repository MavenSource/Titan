"""
AI/ML Model Loader
==================

This module handles loading of AI/ML models at system startup.
It validates model paths, checks file existence, and provides graceful degradation
if models are missing or corrupted.

Models are loaded based on environment variables:
- CATBOOST_MODEL_PATH: CatBoost gradient boosting model
- HF_MODEL_PATH: HuggingFace transformer model
- ML_MODEL_PATH: General ML model (scikit-learn, etc.)
- SELF_LEARNING_DATA_PATH: Self-learning training data directory
- MODEL_CACHE_DIR: Model cache directory

If ENABLE_REALTIME_TRAINING=false, model loading is skipped entirely.
"""

import os
import logging
from pathlib import Path
from typing import Dict, Optional, Any

logger = logging.getLogger("ModelLoader")


class ModelLoader:
    """
    Centralized model loading and validation for Titan AI/ML system.
    """
    
    def __init__(self):
        self.models: Dict[str, Any] = {}
        self.model_paths: Dict[str, Path] = {}
        self.warnings: list = []
        self.errors: list = []
        
        # Read environment variables
        self.enable_training = self._parse_bool(os.getenv('ENABLE_REALTIME_TRAINING', 'true'))
        
        # Model paths from environment
        self.catboost_path = os.getenv('CATBOOST_MODEL_PATH', 'models/catboost_profit_predictor.cbm')
        self.hf_path = os.getenv('HF_MODEL_PATH', 'models/huggingface/market-sentiment')
        self.ml_path = os.getenv('ML_MODEL_PATH', 'models/ml_ensemble_model.pkl')
        self.self_learning_path = os.getenv('SELF_LEARNING_DATA_PATH', 'data/self_learning')
        self.cache_dir = os.getenv('MODEL_CACHE_DIR', 'models/cache')
        
    def _parse_bool(self, value: str) -> bool:
        """Parse boolean from environment variable"""
        if not value:
            return False
        return value.lower() in ('true', '1', 'yes', 'on')
    
    def _is_stub_file(self, filepath: Path) -> bool:
        """Check if a file is a stub/placeholder"""
        if not filepath.exists():
            return False
        
        # Stub files are typically very small (< 1KB)
        if filepath.stat().st_size < 1024:
            # Check if it contains stub indicators
            try:
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read(500)  # Read first 500 bytes
                    stub_indicators = ['stub', 'placeholder', 'replace with', 'not trained']
                    return any(indicator.lower() in content.lower() for indicator in stub_indicators)
            except:
                pass
        
        return False
    
    def validate_paths(self) -> Dict[str, bool]:
        """
        Validate all model paths and return status dictionary.
        
        Returns:
            Dict with model names as keys and existence status as values
        """
        if not self.enable_training:
            logger.info("üîß Real-time training disabled - skipping model validation")
            return {}
        
        logger.info("üîç Validating AI/ML model paths...")
        
        results = {}
        
        # Validate CatBoost model
        catboost_file = Path(self.catboost_path)
        if catboost_file.exists():
            if self._is_stub_file(catboost_file):
                self.warnings.append(f"CatBoost model is a stub file: {self.catboost_path}")
                logger.warning(f"‚ö†Ô∏è  CatBoost model is a stub/placeholder: {self.catboost_path}")
                logger.warning(f"   System will continue without CatBoost predictions")
                results['catboost'] = False
            else:
                logger.info(f"‚úÖ CatBoost model found: {self.catboost_path}")
                results['catboost'] = True
        else:
            self.warnings.append(f"CatBoost model not found: {self.catboost_path}")
            logger.warning(f"‚ö†Ô∏è  CatBoost model not found: {self.catboost_path}")
            logger.warning(f"   System will continue without CatBoost predictions")
            results['catboost'] = False
        
        # Validate HuggingFace model
        hf_dir = Path(self.hf_path)
        if hf_dir.exists() and hf_dir.is_dir():
            # Check for essential HF model files
            has_config = (hf_dir / 'config.json').exists()
            has_model = (hf_dir / 'pytorch_model.bin').exists() or (hf_dir / 'model.safetensors').exists()
            
            if has_config and has_model:
                logger.info(f"‚úÖ HuggingFace model found: {self.hf_path}")
                results['huggingface'] = True
            else:
                self.warnings.append(f"HuggingFace model incomplete: {self.hf_path}")
                logger.warning(f"‚ö†Ô∏è  HuggingFace model directory incomplete: {self.hf_path}")
                logger.warning(f"   Missing: {'config.json' if not has_config else 'model weights'}")
                logger.warning(f"   System will continue without HuggingFace models")
                results['huggingface'] = False
        else:
            self.warnings.append(f"HuggingFace model directory not found: {self.hf_path}")
            logger.warning(f"‚ö†Ô∏è  HuggingFace model directory not found: {self.hf_path}")
            logger.warning(f"   System will continue without HuggingFace models")
            results['huggingface'] = False
        
        # Validate ML ensemble model
        ml_file = Path(self.ml_path)
        if ml_file.exists():
            if self._is_stub_file(ml_file):
                self.warnings.append(f"ML ensemble model is a stub file: {self.ml_path}")
                logger.warning(f"‚ö†Ô∏è  ML ensemble model is a stub/placeholder: {self.ml_path}")
                logger.warning(f"   System will continue without ensemble predictions")
                results['ml_ensemble'] = False
            else:
                logger.info(f"‚úÖ ML ensemble model found: {self.ml_path}")
                results['ml_ensemble'] = True
        else:
            self.warnings.append(f"ML ensemble model not found: {self.ml_path}")
            logger.warning(f"‚ö†Ô∏è  ML ensemble model not found: {self.ml_path}")
            logger.warning(f"   System will continue without ensemble predictions")
            results['ml_ensemble'] = False
        
        # Validate self-learning data directory
        sl_dir = Path(self.self_learning_path)
        if sl_dir.exists() and sl_dir.is_dir():
            logger.info(f"‚úÖ Self-learning data directory found: {self.self_learning_path}")
            results['self_learning_data'] = True
        else:
            logger.info(f"üìÅ Creating self-learning data directory: {self.self_learning_path}")
            try:
                sl_dir.mkdir(parents=True, exist_ok=True)
                logger.info(f"‚úÖ Self-learning data directory created")
                results['self_learning_data'] = True
            except Exception as e:
                self.warnings.append(f"Failed to create self-learning directory: {e}")
                logger.warning(f"‚ö†Ô∏è  Failed to create self-learning directory: {e}")
                results['self_learning_data'] = False
        
        # Validate cache directory
        cache_path = Path(self.cache_dir)
        if cache_path.exists() and cache_path.is_dir():
            logger.info(f"‚úÖ Model cache directory found: {self.cache_dir}")
            results['cache_dir'] = True
        else:
            logger.info(f"üìÅ Creating model cache directory: {self.cache_dir}")
            try:
                cache_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"‚úÖ Model cache directory created")
                results['cache_dir'] = True
            except Exception as e:
                self.warnings.append(f"Failed to create cache directory: {e}")
                logger.warning(f"‚ö†Ô∏è  Failed to create cache directory: {e}")
                results['cache_dir'] = False
        
        # Summary
        available_models = sum(1 for v in results.values() if v)
        total_models = len(results)
        
        logger.info("=" * 70)
        logger.info(f"üìä Model Validation Summary: {available_models}/{total_models} available")
        
        if available_models == 0:
            logger.warning("‚ö†Ô∏è  No external ML models available - using built-in Q-learning only")
            logger.info("üí° To add models, see: models/README.md")
        elif available_models < total_models:
            logger.info("‚ÑπÔ∏è  Some models missing - system will use available models only")
            logger.info("üí° To add missing models, see: models/README.md")
        else:
            logger.info("üéâ All ML models and directories validated successfully!")
        
        logger.info("=" * 70)
        
        return results
    
    def load_models(self) -> Dict[str, Any]:
        """
        Load all available models into memory.
        
        Returns:
            Dict of loaded model objects
        """
        if not self.enable_training:
            logger.info("‚ÑπÔ∏è  Real-time training disabled - skipping model loading")
            return {}
        
        logger.info("üîÑ Loading AI/ML models...")
        
        validation_results = self.validate_paths()
        
        # Note: Actual model loading would happen here
        # For now, we just validate paths and provide infrastructure
        # Real loading requires installing catboost, transformers, etc.
        
        loaded_models = {}
        
        # CatBoost model loading (requires catboost package)
        if validation_results.get('catboost', False):
            try:
                # This would be the actual loading code:
                # from catboost import CatBoostClassifier
                # loaded_models['catboost'] = CatBoostClassifier()
                # loaded_models['catboost'].load_model(self.catboost_path)
                logger.info("‚ÑπÔ∏è  CatBoost model ready (install 'catboost' package to use)")
                loaded_models['catboost'] = None  # Placeholder
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Failed to load CatBoost model: {e}")
        
        # HuggingFace model loading (requires transformers package)
        if validation_results.get('huggingface', False):
            try:
                # This would be the actual loading code:
                # from transformers import AutoModel, AutoTokenizer
                # loaded_models['hf_model'] = AutoModel.from_pretrained(self.hf_path)
                # loaded_models['hf_tokenizer'] = AutoTokenizer.from_pretrained(self.hf_path)
                logger.info("‚ÑπÔ∏è  HuggingFace model ready (install 'transformers' package to use)")
                loaded_models['huggingface'] = None  # Placeholder
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Failed to load HuggingFace model: {e}")
        
        # ML ensemble model loading (requires scikit-learn)
        if validation_results.get('ml_ensemble', False):
            try:
                # This would be the actual loading code:
                # import joblib
                # loaded_models['ml_ensemble'] = joblib.load(self.ml_path)
                logger.info("‚ÑπÔ∏è  ML ensemble model ready (install 'scikit-learn' package to use)")
                loaded_models['ml_ensemble'] = None  # Placeholder
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Failed to load ML ensemble model: {e}")
        
        self.models = loaded_models
        
        if loaded_models:
            logger.info(f"‚úÖ Model loading complete: {len(loaded_models)} model(s) ready")
        else:
            logger.info("‚ÑπÔ∏è  No external models loaded - using built-in Q-learning")
        
        return loaded_models
    
    def get_model(self, model_name: str) -> Optional[Any]:
        """Get a loaded model by name"""
        return self.models.get(model_name)
    
    def get_warnings(self) -> list:
        """Get list of warnings from model loading"""
        return self.warnings
    
    def get_errors(self) -> list:
        """Get list of errors from model loading"""
        return self.errors


def initialize_models() -> ModelLoader:
    """
    Initialize and validate all AI/ML models.
    
    This is the main entry point for model loading at system startup.
    Call this function during application initialization.
    
    Returns:
        ModelLoader instance with validation results
    """
    loader = ModelLoader()
    loader.load_models()
    return loader


if __name__ == "__main__":
    # Test model loader
    import sys
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - [%(name)s] %(message)s'
    )
    
    print("=" * 70)
    print("  AI/ML MODEL LOADER - VALIDATION TEST")
    print("=" * 70)
    print("")
    
    loader = initialize_models()
    
    print("")
    print("=" * 70)
    print("  VALIDATION COMPLETE")
    print("=" * 70)
    
    if loader.get_warnings():
        print("\n‚ö†Ô∏è  Warnings:")
        for warning in loader.get_warnings():
            print(f"  - {warning}")
    
    if loader.get_errors():
        print("\n‚ùå Errors:")
        for error in loader.get_errors():
            print(f"  - {error}")
    
    print("\n‚úÖ Model loader test complete")
